{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of HyFlux StormSurge Med results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is part of an effort to figure out a discepancy with hyflux data and a time phase of 6 hours in the Med Sea storm surge calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import glob\n",
    "import numpy as np\n",
    "from pmap import getmap\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today=datetime.datetime.today()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH='/mnt/ECMWF/processed/{}/FIX_MED_SEA/'.format(today.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tstamp='20160616.00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hfiles=glob.glob(PATH+'calc_{}/TIF_H*.tif'.format(tstamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print hfiles[0].split('/')[-1].split('_H_')[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t=[]\n",
    "for k in hfiles:\n",
    "    t.append(k.split('/')[-1].split('_H_')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time=np.array(t)\n",
    "print time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we parse the bathymetry tif to get the i,j of the point in question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename=PATH+'calc_{}/bathymetry.tif'.format(tstamp)\n",
    "grid = getmap(filename)\n",
    "\n",
    "gt=grid.GeoTr\n",
    "\n",
    "width=grid.NCOLS\n",
    "height=grid.NROWS\n",
    "\n",
    "minx = gt[0]\n",
    "miny = gt[3] + width*gt[4] + height*gt[5]\n",
    "maxx = gt[0] + width*gt[1] + height*gt[2]\n",
    "maxy = gt[3]\n",
    "\n",
    "lon=np.linspace(minx,maxx,width,endpoint=True)\n",
    "lat=np.linspace(miny,maxy,height,endpoint=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the lat/lon we want. First we load the file with the observation points we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OFILE='/mnt/pandora/Projects_Critech/EX_2015_CoastAlRisk/maps/data/s_b_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs=pandas.read_csv(OFILE,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a point e.g. 1858 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plat,plon=obs['latcalc'][12],obs['loncalc'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print plat,plon # check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the i,j for this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=np.abs(lat-plat).argmin()\n",
    "j=np.abs(lon-plon).argmin()\n",
    "print i,j, lat[i-1:i+2],lon[j-1:j+2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: How did we compute these calc points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we parse the geotif files ad select the i,j value adding it to a new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hobs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat=getmap(hfiles[0])\n",
    "dat.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need to flip upside down the data to get the correct i,j (inherit to the geotif coordination system ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ifile in hfiles:\n",
    "    dat=getmap(ifile)\n",
    "    hobs.append(np.flipud(dat.data)[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hobs=np.array(hobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally we can plot. Note that the time stamp on the time array are seconds passed from a certain starting point. How to determine that? One way is to parse the file Calc_input_deck.txt where the InTime and Fin Time is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(PATH+'calc_{}/Calc_input_deck.txt'.format(tstamp)) as f:\n",
    "     lines = [line.rstrip('\\n') for line in f]\n",
    "     for atr in lines:\n",
    "        if 'InTime' in atr: time1 = atr.split('*')[0]\n",
    "        if 'FinTime' in atr: time2 = atr.split('*')[0]\n",
    "        if 'DateTsunami' in atr: startime=atr.split('*')[0]\n",
    "f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print intime,fintime, startime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intime=float(time1.split('=')[1])\n",
    "fintime=float(time2.split('=')[1])\n",
    "stime=startime.split('=')[1].strip()\n",
    "print intime,fintime,stime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the starting time of this run is ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odate=datetime.datetime.strptime(stime,'%d %b %Y %H:%S')\n",
    "print sdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the start time of this particular computation is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print odate+datetime.timedelta(hours=intime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " while the time stamp on the file is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tstamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thus the computation starts 6 hours before.!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parsing for all folders in this year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allfolders=glob.glob(PATH+'calc_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders=allfolders[-10:]# last 10 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y %H'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.HourLocator(byhour=[0,12]))\n",
    "ax.xaxis_date()\n",
    "\n",
    "for ifolder in folders: \n",
    "    rstamp=ifolder.split('/')[-1].split('_')[1] # the time stamp on the run folder (actual date of the run)\n",
    "    rdate=datetime.datetime.strptime(rstamp,'%Y%m%d.%H')\n",
    "    hfiles=glob.glob(ifolder+'/TIF_H*.tif')\n",
    "    t=[]\n",
    "    hobs=[]\n",
    "    for ifile in hfiles:  \n",
    "        dat=getmap(ifile)\n",
    "        hobs.append(np.flipud(dat.data)[i,j])\n",
    "        ti=ifile.split('/')[-1].split('_H_')[1].split('.')[0]\n",
    "        if ti == 0: # there is a new restart\n",
    "            t.append(rdate)\n",
    "            odate=rdate # set new odate\n",
    "        else:\n",
    "            t.append(odate+datetime.timedelta(hours=float(ti)/60./60.))\n",
    "    plt.plot(t,hobs,'o-',label=rdate)\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the elevation for the 6 hours before the run's main time stamp do not match. WHY? What changed? What is the one one will use for a long time series? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the forcing files in the time folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allfolders=glob.glob(PATH+'tif_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folders=allfolders[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdic={}  # create a dictionary to store the timestamps of every run(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ifolder in folders: \n",
    "    rstamp=ifolder.split('/')[-1].split('_')[1] # the time stamp on the run folder (actual date of the run)\n",
    "    rdate=datetime.datetime.strptime(rstamp,'%Y%m%d.%H')\n",
    "    pfiles=glob.glob(ifolder+'/TIF_PRESS*.tif')\n",
    "    t=[]\n",
    "    for ifile in pfiles:\n",
    "        ti=ifile.split('/')[-1].split('_PRESS_')[1].split('.')[0]\n",
    "        ta=datetime.datetime.strptime(ti,'%Y%m%d%H%M')\n",
    "        t.append(ta)\n",
    "    fdic[rstamp]=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in range(1,np.size(folders)):\n",
    "    rstamp=folders[m].split('/')[-1].split('_')[1] \n",
    "    foldertime=datetime.datetime.strptime(rstamp,'%Y%m%d.%H')\n",
    "    previous_stamp=folders[m-1].split('/')[-1].split('_')[1]\n",
    "    pfiles=glob.glob(folders[m]+'/TIF_PRESS*.tif')\n",
    "    for ifile in pfiles:\n",
    "        ti=ifile.split('/')[-1].split('_PRESS_')[1].split('.')[0]\n",
    "        ta=datetime.datetime.strptime(ti,'%Y%m%d%H%M')\n",
    "        if ta < foldertime and ta in fdic[previous_stamp]:\n",
    "            print 'check {}'.format(ta)\n",
    "            dprev=getmap(folders[m-1]+'/TIF_PRESS_'+ti+'.tif')\n",
    "            dcur=getmap(folders[m]+'/TIF_PRESS_'+ti+'.tif')\n",
    "            #compare data\n",
    "            if not np.array_equal(dprev.data,dcur.data) : print 'error in {}'.format(ta)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same thing for U,V, VMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in range(1,np.size(folders)):\n",
    "    rstamp=folders[m].split('/')[-1].split('_')[1] \n",
    "    foldertime=datetime.datetime.strptime(rstamp,'%Y%m%d.%H')\n",
    "    previous_stamp=folders[m-1].split('/')[-1].split('_')[1]\n",
    "    pfiles=glob.glob(folders[m]+'/TIF_U10*.tif')\n",
    "    for ifile in pfiles:\n",
    "        ti=ifile.split('/')[-1].split('_U10_')[1].split('.')[0]\n",
    "        ta=datetime.datetime.strptime(ti,'%Y%m%d%H%M')\n",
    "        if ta < foldertime and ta in fdic[previous_stamp]:\n",
    "            print 'check {}'.format(ta)\n",
    "            dprev=getmap(folders[m-1]+'/TIF_U10_'+ti+'.tif')\n",
    "            dcur=getmap(folders[m]+'/TIF_U10_'+ti+'.tif')\n",
    "            #compare data\n",
    "            if not np.array_equal(dprev.data,dcur.data) : print 'error in {}'.format(ta)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in range(1,np.size(folders)):\n",
    "    rstamp=folders[m].split('/')[-1].split('_')[1] \n",
    "    foldertime=datetime.datetime.strptime(rstamp,'%Y%m%d.%H')\n",
    "    previous_stamp=folders[m-1].split('/')[-1].split('_')[1]\n",
    "    pfiles=glob.glob(folders[m]+'/TIF_V10*.tif')\n",
    "    for ifile in pfiles:\n",
    "        ti=ifile.split('/')[-1].split('_V10_')[1].split('.')[0]\n",
    "        ta=datetime.datetime.strptime(ti,'%Y%m%d%H%M')\n",
    "        if ta < foldertime and ta in fdic[previous_stamp]:\n",
    "            print 'check {}'.format(ta)\n",
    "            dprev=getmap(folders[m-1]+'/TIF_V10_'+ti+'.tif')\n",
    "            dcur=getmap(folders[m]+'/TIF_V10_'+ti+'.tif')\n",
    "            #compare data\n",
    "            if not np.array_equal(dprev.data,dcur.data) : print 'error in {}'.format(ta)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in range(1,np.size(folders)):\n",
    "    rstamp=folders[m].split('/')[-1].split('_')[1] \n",
    "    foldertime=datetime.datetime.strptime(rstamp,'%Y%m%d.%H')\n",
    "    previous_stamp=folders[m-1].split('/')[-1].split('_')[1]\n",
    "    pfiles=glob.glob(folders[m]+'/VMAX_*.tif')\n",
    "    for ifile in pfiles:\n",
    "        ti=ifile.split('/')[-1].split('VMAX_')[1].split('.')[0]\n",
    "        ta=datetime.datetime.strptime(ti,'%Y%m%d%H%M')\n",
    "        if ta < foldertime and ta in fdic[previous_stamp]:\n",
    "            print 'check {}'.format(ta)\n",
    "            dprev=getmap(folders[m-1]+'/VMAX_'+ti+'.tif')\n",
    "            dcur=getmap(folders[m]+'/VMAX_'+ti+'.tif')\n",
    "            #compare data\n",
    "            if not np.array_equal(dprev.data,dcur.data) : print 'error in {}'.format(ta)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dprev.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dcur.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So input files are the same !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we compare the values on the NETCDF files with the one above from the geotif files. For the retrieval of data from the netcdf see ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
